{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 100, 'reps': 5, 'N': 60, 'proc': 3, 'T': 1, 'Y': 'ch4_flux'}\n"
     ]
    }
   ],
   "source": [
    "class Params:\n",
    "    def __init__(self,Func,Y):\n",
    "        if Func == 'Quick':            \n",
    "            epochs = 1000\n",
    "            reps = 10\n",
    "            N = 300\n",
    "            T = 6\n",
    "        elif Func == 'Full':\n",
    "            epochs = 2000\n",
    "            reps = 100\n",
    "            N = 200\n",
    "            T = 12\n",
    "        else:\n",
    "            epochs = 100\n",
    "            reps = 5\n",
    "            N = 60\n",
    "            T = 1\n",
    "        self.params = {}\n",
    "        self.params['T'] = T\n",
    "        self.params['N'] = N\n",
    "        self.params['reps'] = reps\n",
    "        self.params['epochs'] = epochs\n",
    "        self.params['Y'] = Y\n",
    "        self.params['proc']=3\n",
    "\n",
    "rpms = Params('temp','ch4_flux')\n",
    "params=rpms.params\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReadStandardTime:\n",
    "    def __init__(self,Path):\n",
    "        self.Master = pd.read_csv(Path,delimiter = ',',header = 0,na_values = -9999)\n",
    "        self.Master = self.Master.set_index(pd.DatetimeIndex(pd.to_datetime(self.Master['datetime'])))\n",
    "        self.Master['DOY'] = self.Master.index.dayofyear*1.0\n",
    "        self.Master['HR'] = self.Master.index.hour*1.0\n",
    "        \n",
    "    def Scale(self,y_var,X_vars):\n",
    "        self.y_var = y_var\n",
    "        self.Data = self.Master[np.isfinite(self.Master[y_var])]\n",
    "        self.Data = self.Data.interpolate().bfill()\n",
    "        self.Data = self.Data.interpolate().ffill()\n",
    "        self.y = self.Data[y_var].values\n",
    "        YStandard = StandardScaler()\n",
    "        self.YScaled = YStandard.fit(self.y.reshape(-1, 1))\n",
    "        Yscale = self.YScaled.transform(self.y.reshape(-1, 1))\n",
    "        self.y = np.ndarray.flatten(Yscale)\n",
    "        self.Ytru = self.YScaled.inverse_transform(self.y.reshape(-1,1))\n",
    "        X = self.Data[X_vars]\n",
    "        self.input_shape = len(X_vars)\n",
    "        XStandard = StandardScaler()\n",
    "        self.XScaled= XStandard.fit(X)\n",
    "        self.X = self.XScaled.transform(X)\n",
    "        Filling = self.Master[X_vars]\n",
    "        Filling = Filling.interpolate().bfill()\n",
    "        Filling = Filling.interpolate().ffill()\n",
    "        XStandard = StandardScaler()\n",
    "        self.XFillScaled= XStandard.fit(Filling)\n",
    "        self.X_fill = self.XScaled.transform(Filling)\n",
    "        \n",
    "    def TimeShape(self,rolls):\n",
    "        X1 = self.X\n",
    "        Xf = self.X_fill\n",
    "        self.X_time = np.zeros(shape = (X1.shape[0],rolls+1,X1.shape[1]))\n",
    "        self.X_time[:,0,:] = X1\n",
    "        self.X_ftime = np.zeros(shape = (Xf.shape[0],rolls+1,Xf.shape[1]))\n",
    "        self.X_ftime[:,0,:] = Xf\n",
    "        if rolls > 0:\n",
    "            for roll in range(0,rolls):\n",
    "                X2 = np.roll(X1,(roll+1),axis=0)\n",
    "                X2f = np.roll(Xf,(roll+1),axis=0)\n",
    "                self.X_time[:,roll+1,:] = X2\n",
    "                self.X_ftime[:,roll+1,:] = Xf\n",
    "        self.X_time = self.X_time[rolls+1:,:,:]\n",
    "        self.X_ftime = self.X_ftime[rolls+1:,:,:]\n",
    "        self.y_time = self.y[rolls+1:]\n",
    "        self.y_ftime = self.y[rolls+1:]\n",
    "        self.TimeSteps = rolls+1\n",
    "        \n",
    "    def Fill(self,Y_Pred):\n",
    "        Y_fill = self.YScaled.inverse_transform(Y_Pred.reshape(-1,1))\n",
    "        nanz = np.zeros(shape=(self.TimeSteps,1))\n",
    "        nanz[:,:] = np.nan\n",
    "        Y_Pred = np.concatenate((nanz,Y_fill),axis=0).reshape(-1,1)\n",
    "        self.Master['TempFIll'] = Y_Pred\n",
    "        self.Master[self.y_var+'_Filled'] = self.Master[self.y_var].fillna(self.Master['TempFIll'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LSTM_Model(Neurons,batch_size,time_steps,inputs,lr=1e-4,Memory=.9):\n",
    "    import keras\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    from keras.layers import LSTM\n",
    "    from keras.wrappers.scikit_learn import KerasRegressor\n",
    "    from keras.callbacks import EarlyStopping,ModelCheckpoint,LearningRateScheduler\n",
    "#     from keras import backend as K\n",
    "    import tensorflow as tf\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = Memory\n",
    "    session = tf.Session(config=config)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(Neurons, input_shape=(time_steps,inputs),stateful = False))\n",
    "    model.add(Dense(1))\n",
    "#     NUM_GPU = 1 # or the number of GPUs available on machine # - Add if using MXNET\n",
    "#     adam = keras.optimizers.Adam(lr = lr)\n",
    "#     gpu_list = []\n",
    "#     for i in range(NUM_GPU): gpu_list.append('gpu(%d)' % i)\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')#,context=gpu_list) # - Add if using MXNET\n",
    "    return(model)\n",
    "\n",
    "def Train_Steps(epochs,Neurons,X_train,X_test,X_val,y_train,y_test,y_val,i,Memory=None):\n",
    "    \n",
    "    np.random.seed(i)\n",
    "    from keras import backend as K\n",
    "    Scorez=[]\n",
    "    lr = 1e-3\n",
    "    Mod = LSTM_Model(Neurons,X_train.shape[0],X_train.shape[1],X_train.shape[2],lr=lr,Memory=Memory)\n",
    "    killscore=0\n",
    "    killmax = 10\n",
    "    e = 0\n",
    "    udate = 3\n",
    "    while killscore < killmax and e < epochs:\n",
    "        Mod.fit(X_train,y_train,batch_size=X_train.shape[0], nb_epoch=1,shuffle=True,verbose=0)\n",
    "        old_weights = Mod.get_weights()\n",
    "        Y = Mod.predict(X_test,batch_size =X_test.shape[0])\n",
    "        score = metrics.mean_squared_error(y_test,Y)\n",
    "        Scorez.append(score)\n",
    "        if e == 0:\n",
    "            score_min=score\n",
    "            min_weights=old_weights\n",
    "        elif score < score_min:\n",
    "            score_min = score\n",
    "            min_weights=old_weights\n",
    "            killscore = 0\n",
    "        else:\n",
    "            killscore +=1\n",
    "        if killscore == math.floor(killmax/2):\n",
    "            K.set_value(Mod.optimizer.lr, 0.5 * K.get_value(Mod.optimizer.lr))\n",
    "        Mod.reset_states()\n",
    "        e +=1\n",
    "    Mod.set_weights(min_weights)\n",
    "    Yval = Mod.predict(X_val,batch_size = X_val.shape[0])\n",
    "    MSE = (metrics.mean_squared_error(y_val,Yval))\n",
    "    Scorez=np.asanyarray(Scorez)\n",
    "    return(MSE)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Factor:  u*\n",
      "Level:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217.12630677223206\n"
     ]
    }
   ],
   "source": [
    "def Combos(Model,L,factor=None):\n",
    "    Models=list()\n",
    "    for c in combinations(Model,L):\n",
    "        c = list(c)\n",
    "        if factor == None:\n",
    "            Models.append(c)\n",
    "        else:\n",
    "            if factor in c:\n",
    "                Models.append(c)\n",
    "    return(Models)\n",
    "\n",
    "def TTV_Split(i,Memory,X,y,params):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.1, random_state=i)\n",
    "    X_train,X_val,y_train,y_val=train_test_split(X_train,y_train, test_size=0.11, random_state=i)\n",
    "    return(Train_Steps(params['epochs'],params['N'],X_train,X_test,X_val,y_train,y_test,y_val,i=i,Memory=Memory))\n",
    "\n",
    "Model = ['Temp_2_5_1','u*','air_pressure','Table_1']#,'NR_Wm2_Avg','AirTC_Avg','RH','DOY']\n",
    "Time = time.time()\n",
    "\n",
    "Path = 'QuickData_FI.csv' \n",
    "def RunReps(Model,params,pool = None):\n",
    "    RST = ReadStandardTime(Path)\n",
    "    offset = 5/params['proc']\n",
    "    Memory = (math.floor(100/params['proc'])- offset) * .01\n",
    "    MSE = []\n",
    "    RST.Scale(params['Y'],Model)\n",
    "    RST.TimeShape(params['T'])\n",
    "    y = RST.y_time*1.0\n",
    "    X = RST.X_time*1.0\n",
    "    MSE = []\n",
    "    if __name__=='__main__'and params['proc'] != 1:\n",
    "#         pool = Pool(processes=params['proc'],maxtasksperchild=50)\n",
    "        for i,mse in enumerate(pool.imap(partial(TTV_Split,Memory=Memory,X=X,y=y,params=params),range(params['reps']))):\n",
    "            MSE.append(mse)\n",
    "#         pool.close()\n",
    "    else:\n",
    "        for i in range(params['reps']):\n",
    "            mse = TTV_Split(i,Memory,X,y,params)\n",
    "            MSE.append(mse)\n",
    "    MSE = np.asanyarray(MSE)\n",
    "    return(MSE)\n",
    "    \n",
    "Scores = []\n",
    "L = len(Model)-1\n",
    "Models = Combos(Model,L)\n",
    "\n",
    "if __name__=='__main__'and params['proc'] != 1:\n",
    "    pool = Pool(processes=params['proc'],maxtasksperchild=50)\n",
    "else:pool=None\n",
    "while L > 0:\n",
    "    print('Level: ', L)\n",
    "    Score = []\n",
    "    for i in range(len(Models)):\n",
    "\n",
    "        Results = RunReps(Models[i],params,pool)\n",
    "        Score.append(Results.mean())\n",
    "    Score = np.asanyarray(Score)\n",
    "    \n",
    "    Worst = Models[np.where(Score == Score.max())[0][0]]\n",
    "    Best = Models[np.where(Score == Score.min())[0][0]]\n",
    "    Scores.append(Score)\n",
    "    L-=1\n",
    "    if L >1:\n",
    "        for factor in Best:\n",
    "            if factor not in Worst:\n",
    "                print('Best Factor: ', factor)\n",
    "                Models = Combos(Model,L,factor)\n",
    "    else:\n",
    "        Models=[Best]\n",
    "print('Best Factor: ',Best)\n",
    "print(time.time()-Time)\n",
    "if __name__=='__main__'and params['proc'] != 1:\n",
    "    pool.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzwAAAHVCAYAAAA0Iv6NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f35ad4fe748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "Scores = np.asanyarray(Scores)\n",
    "plt.boxplot(Scores)\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
