{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 8)\n",
    "\n",
    "Analyze = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params:\n",
    "    def __init__(self,Func,Y):\n",
    "        if Func == 'Full':\n",
    "            epochs = 1000\n",
    "            reps = 100\n",
    "        else:\n",
    "            epochs = 50\n",
    "            reps = 3\n",
    "        if Y == 'co2_flux':\n",
    "            N = 23\n",
    "            T = 0\n",
    "        else:\n",
    "            N = 82\n",
    "            T = 2\n",
    "        self.params = {}\n",
    "        self.params['T'] = T\n",
    "        self.params['N'] = N\n",
    "        self.params['reps'] = reps\n",
    "        self.params['epochs'] = epochs\n",
    "        self.params['Y'] = Y\n",
    "        self.params['proc']=3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LSTM_Model(Neurons,batch_size,time_steps,inputs,lr=1e-4,Memory=.9):\n",
    "    import keras\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    from keras.layers import LSTM\n",
    "    from keras.wrappers.scikit_learn import KerasRegressor\n",
    "    from keras.callbacks import EarlyStopping,ModelCheckpoint,LearningRateScheduler\n",
    "#     from keras import backend as K\n",
    "    import tensorflow as tf\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = Memory\n",
    "    session = tf.Session(config=config)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(Neurons, input_shape=(time_steps,inputs),stateful = False))\n",
    "    model.add(Dense(1))\n",
    "#     NUM_GPU = 1 # or the number of GPUs available on machine # - Add if using MXNET\n",
    "#     adam = keras.optimizers.Adam(lr = lr)\n",
    "#     gpu_list = []\n",
    "#     for i in range(NUM_GPU): gpu_list.append('gpu(%d)' % i)\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')#,context=gpu_list) # - Add if using MXNET\n",
    "    return(model)\n",
    "\n",
    "def Train_Steps(epochs,Neurons,X_train,X_test,X_val,y_train,y_test,y_val,i,Memory=None,\n",
    "                GapFill=None,FullX=None):\n",
    "    \n",
    "    np.random.seed(i)\n",
    "    from keras import backend as K\n",
    "    Scorez=[]\n",
    "    lr = 1e-3\n",
    "    Mod = LSTM_Model(Neurons,X_train.shape[0],X_train.shape[1],X_train.shape[2],lr=lr,Memory=Memory)\n",
    "    killscore=0\n",
    "    killmax = 10\n",
    "    e = 0\n",
    "    udate = 3\n",
    "    while killscore < killmax and e < epochs:\n",
    "        Mod.fit(X_train,y_train,batch_size=X_train.shape[0], nb_epoch=1,shuffle=True,verbose=0)\n",
    "        old_weights = Mod.get_weights()\n",
    "        Y = Mod.predict(X_test,batch_size =X_test.shape[0])\n",
    "        score = metrics.mean_squared_error(y_test,Y)\n",
    "        Scorez.append(score)\n",
    "        if e == 0:\n",
    "            score_min=score\n",
    "            min_weights=old_weights\n",
    "        elif score < score_min:\n",
    "            score_min = score\n",
    "            min_weights=old_weights\n",
    "            killscore = 0\n",
    "        else:\n",
    "            killscore +=1\n",
    "        if killscore == math.floor(killmax/2):\n",
    "            K.set_value(Mod.optimizer.lr, 0.5 * K.get_value(Mod.optimizer.lr))\n",
    "        Mod.reset_states()\n",
    "        e +=1\n",
    "    Mod.set_weights(min_weights)\n",
    "    Yval = Mod.predict(X_val,batch_size = X_val.shape[0])\n",
    "    MSE = (metrics.mean_squared_error(y_val,Yval))\n",
    "    Scorez=np.asanyarray(Scorez)\n",
    "    if GapFill == None:\n",
    "        return(MSE)\n",
    "    else:\n",
    "        return(Mod.predict(FullX,batch_size=FullX.shape[0]))\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReadStandardTime:\n",
    "    def __init__(self,Path):\n",
    "        self.Path=Path\n",
    "        self.Master = pd.read_csv(Path,delimiter = ',',header = 0,na_values = -9999)\n",
    "        self.Master = self.Master.set_index(pd.DatetimeIndex(pd.to_datetime(self.Master['datetime'])))\n",
    "        self.Master['DOY'] = self.Master.index.dayofyear*1.0\n",
    "        self.Master['HR'] = self.Master.index.hour*1.0\n",
    "        \n",
    "    def Scale(self,y_var,X_vars):\n",
    "        self.y_var = y_var\n",
    "        self.Data = self.Master[np.isfinite(self.Master[y_var])]\n",
    "                           \n",
    "        self.Data = self.Data.interpolate().bfill()\n",
    "        self.Data = self.Data.interpolate().ffill()\n",
    "        self.y = self.Data[y_var].values\n",
    "        YStandard = StandardScaler()\n",
    "        self.YScaled = YStandard.fit(self.y.reshape(-1, 1))\n",
    "        Yscale = self.YScaled.transform(self.y.reshape(-1, 1))\n",
    "        self.y = np.ndarray.flatten(Yscale)\n",
    "        self.Ytru = self.YScaled.inverse_transform(self.y.reshape(-1,1))\n",
    "        X = self.Data[X_vars]\n",
    "        self.input_shape = len(X_vars)\n",
    "        XStandard = StandardScaler()\n",
    "        self.XScaled= XStandard.fit(X)\n",
    "        self.X = self.XScaled.transform(X)\n",
    "        Filling = self.Master[X_vars]\n",
    "        Filling = Filling.interpolate().bfill()\n",
    "        Filling = Filling.interpolate().ffill()\n",
    "        XStandard = StandardScaler()\n",
    "        self.XFillScaled= XStandard.fit(Filling)\n",
    "        self.X_fill = self.XScaled.transform(Filling)\n",
    "        \n",
    "    def TimeShape(self,rolls):\n",
    "        X1 = self.X\n",
    "        Xf = self.X_fill\n",
    "        self.X_time = np.zeros(shape = (X1.shape[0],rolls+1,X1.shape[1]))\n",
    "        self.X_time[:,0,:] = X1\n",
    "        self.X_ftime = np.zeros(shape = (Xf.shape[0],rolls+1,Xf.shape[1]))\n",
    "        self.X_ftime[:,0,:] = Xf\n",
    "        if rolls > 0:\n",
    "            for roll in range(0,rolls):\n",
    "                X2 = np.roll(X1,(roll+1),axis=0)\n",
    "                X2f = np.roll(Xf,(roll+1),axis=0)\n",
    "                self.X_time[:,roll+1,:] = X2\n",
    "                self.X_ftime[:,roll+1,:] = Xf\n",
    "        self.X_time = self.X_time[rolls+1:,:,:]\n",
    "        self.X_ftime = self.X_ftime[rolls+1:,:,:]\n",
    "        self.y_time = self.y[rolls+1:]\n",
    "        self.y_ftime = self.y[rolls+1:]\n",
    "        self.TimeSteps = rolls+1\n",
    "        \n",
    "    def Fill(self,Y_Pred):\n",
    "        Y_fill = self.YScaled.inverse_transform(Y_Pred.reshape(-1,1))\n",
    "        nanz = np.zeros(shape=(self.TimeSteps,1))\n",
    "        nanz[:,:] = np.nan\n",
    "        Y_Pred = np.concatenate((nanz,Y_fill),axis=0).reshape(-1,1)\n",
    "        print(self.Master.shape,Y_Pred.shape)\n",
    "        self.Master['TempFill'] = Y_Pred\n",
    "        self.Master[self.y_var+'_Filled'] = self.Master[self.y_var].fillna(self.Master['TempFill'])\n",
    "#         self.Master.drop('TempFill',inplace=True)\n",
    "        self.Master.to_csv(self.Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Combos(Model,L,factor=None):\n",
    "    Models=list()\n",
    "    for c in combinations(Model,L):\n",
    "        c = list(c)\n",
    "        if factor == None:\n",
    "            Models.append(c)\n",
    "        else:\n",
    "            if factor in c:\n",
    "                Models.append(c)\n",
    "    return(Models)\n",
    "\n",
    "def TTV_Split(i,Memory,X,y,params,GapFill,FullX):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.1, random_state=i)\n",
    "    X_train,X_val,y_train,y_val=train_test_split(X_train,y_train, test_size=0.11, random_state=i)\n",
    "    if GapFill==None:\n",
    "        return(Train_Steps(params['epochs'],params['N'],X_train,X_test,X_val,y_train,y_test,y_val,i=i,Memory=Memory))\n",
    "    else:\n",
    "        return(Train_Steps(params['epochs'],params['N'],X_train,X_test,X_val,y_train,y_test,y_val,i=i,Memory=Memory,\n",
    "                              GapFill=GapFill,FullX=FullX))\n",
    "\n",
    "# Model = ['Temp_2_5_1','u*','air_pressure','Table_1','NR_Wm2_Avg','AirTC_Avg','RH','DOY']\n",
    "\n",
    "\n",
    "Model = [\"DOY\",\"H\",\"air_pressure\",\"wind_speed\",\"wind_dir\",\"u*\",\"Hz\",\"AirTC_Avg\",\"RH_Samp\",\"Rain_mm_Tot\",\"NR_Wm2_Avg\",\n",
    "         \"PPFD_Avg\",\"Temp_2_5_1\",\"Temp_15_1\",\"Temp_5_1\",\"Temp_2_5_2\",\"Temp_15_2\",\"Temp_5_2\",\"Depth_1\",\"Active_Layer_1\",\n",
    "         \"Table_1\",\"Depth_2\",\"Active_Layer_2\"]\n",
    "\n",
    "Time = time.time()\n",
    "\n",
    "Path = 'FI_Data_W_BL.csv' \n",
    "def RunReps(Model,params,pool = None,GapFill=None):\n",
    "    RST = ReadStandardTime(Path)\n",
    "    offset = 5/params['proc']\n",
    "    Memory = (math.floor(100/params['proc'])- offset) * .01\n",
    "    MSE = []\n",
    "    RST.Scale(params['Y'],Model)\n",
    "    RST.TimeShape(params['T'])\n",
    "    y = RST.y_time*1.0\n",
    "    X = RST.X_time*1.0\n",
    "    FullX = RST.X_ftime\n",
    "    MSE = []\n",
    "    Y_Pred = []\n",
    "    if __name__=='__main__'and params['proc'] != 1:\n",
    "        for i,res in enumerate(pool.imap(partial(TTV_Split,Memory=Memory,X=X,y=y,params=params,GapFill=GapFill,FullX=FullX),\n",
    "                                         range(params['reps']))):\n",
    "            if GapFill == None:\n",
    "                MSE.append(res)\n",
    "            else:\n",
    "                Y_Pred.append(res)\n",
    "                \n",
    "    else:\n",
    "        for i in range(params['reps']):\n",
    "            res = TTV_Split(i,Memory,X,y,params,GapFill=GapFill,FullX=FullX)\n",
    "            if GapFill == None:\n",
    "                MSE.append(res)\n",
    "            else:\n",
    "                Y_Pred.append(res)\n",
    "    if GapFill == None:\n",
    "        MSE = np.asanyarray(MSE)\n",
    "        return(MSE)\n",
    "    else:\n",
    "        Y_Pred = np.asanyarray(Y_Pred).mean(axis=0)\n",
    "        RST.Fill(Y_Pred)\n",
    "        print(Y_Pred.shape)\n",
    "        return('kitty')\n",
    "    \n",
    "Scores = []\n",
    "L = len(Model)-1\n",
    "Models = Combos(Model,L)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gap Filling - Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 50, 'N': 23, 'Y': 'co2_flux', 'reps': 3, 'proc': 3, 'T': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4021, 261) (4021, 1)\n",
      "(4020, 1)\n",
      "{'epochs': 50, 'N': 82, 'Y': 'ch4_flux', 'reps': 3, 'proc': 3, 'T': 2}\n",
      "(4021, 262) (4021, 1)\n",
      "(4018, 1)\n"
     ]
    }
   ],
   "source": [
    "pool.close()\n",
    "\n",
    "if __name__=='__main__'and params['proc'] != 1:\n",
    "    pool = Pool(processes=params['proc'],maxtasksperchild=60)\n",
    "else:pool=None\n",
    "    \n",
    "Fluxes = ['co2_flux','ch4_flux']\n",
    "for flux in Fluxes:\n",
    "    rpms = Params('temp',flux)\n",
    "    params=rpms.params\n",
    "    print(params)\n",
    "    Results = RunReps(Model,params,pool,GapFill=True)\n",
    "# Score.append(Results.mean())\n",
    "# Score = np.asanyarray(Score)\n",
    "\n",
    "# Worst = Models[np.where(Score == Score.max())[0][0]]\n",
    "# Best = Models[np.where(Score == Score.min())[0][0]]\n",
    "# Scores.append(Score)\n",
    "# L-=1\n",
    "# if L >1:\n",
    "#     print(Best)\n",
    "#     print(Worst)\n",
    "#     for factor in Best:\n",
    "#         print(factor)\n",
    "#         if factor not in Worst:\n",
    "#             print('Best Factor: ', factor)\n",
    "#             Models = Combos(Best,L,factor)\n",
    "# else:\n",
    "#     Models=[Best]\n",
    "# print()\n",
    "# print('Best Factor: ',Best)\n",
    "# print(time.time()-Time)\n",
    "if __name__=='__main__'and params['proc'] != 1:\n",
    "    pool.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Analyze' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-8af914b9b024>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mAnalyze\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;32mand\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'proc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'proc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxtasksperchild\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mL\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Analyze' is not defined"
     ]
    }
   ],
   "source": [
    "if Analyze == True:\n",
    "    if __name__=='__main__'and params['proc'] != 1:\n",
    "        pool = Pool(processes=params['proc'],maxtasksperchild=60)\n",
    "    else:pool=None\n",
    "    while L > 0:\n",
    "        print('Level: ', L)\n",
    "\n",
    "        print()\n",
    "        print(Models)\n",
    "        print()\n",
    "\n",
    "        Score = []\n",
    "        for i in range(len(Models)):\n",
    "\n",
    "            Results = RunReps(Models[i],params,pool)\n",
    "            Score.append(Results.mean())\n",
    "        Score = np.asanyarray(Score)\n",
    "\n",
    "        Worst = Models[np.where(Score == Score.max())[0][0]]\n",
    "        Best = Models[np.where(Score == Score.min())[0][0]]\n",
    "        Scores.append(Score)\n",
    "        L-=1\n",
    "        if L >1:\n",
    "            print(Best)\n",
    "            print(Worst)\n",
    "            for factor in Best:\n",
    "                print(factor)\n",
    "                if factor not in Worst:\n",
    "                    print('Best Factor: ', factor)\n",
    "                    Models = Combos(Best,L,factor)\n",
    "        else:\n",
    "            Models=[Best]\n",
    "        print()\n",
    "    print('Best Factor: ',Best)\n",
    "    print(time.time()-Time)\n",
    "    if __name__=='__main__'and params['proc'] != 1:\n",
    "        pool.close()\n",
    "\n",
    "    Scores = np.asanyarray(Scores)\n",
    "    plt.boxplot(Scores)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
