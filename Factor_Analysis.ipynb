{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReadStandardTime:\n",
    "    def __init__(self,Path):\n",
    "        self.Master = pd.read_csv(Path,delimiter = ',',header = 0,na_values = -9999)\n",
    "        self.Master = self.Master.set_index(pd.DatetimeIndex(pd.to_datetime(self.Master['datetime'])))\n",
    "        self.Master['DOY'] = self.Master.index.dayofyear*1.0\n",
    "        self.Master['HR'] = self.Master.index.hour*1.0\n",
    "        \n",
    "    def Scale(self,y_var,X_vars):\n",
    "        self.y_var = y_var\n",
    "        self.Data = self.Master[np.isfinite(self.Master[y_var])]\n",
    "        self.Data = self.Data.interpolate().bfill()\n",
    "        self.Data = self.Data.interpolate().ffill()\n",
    "        self.y = self.Data[y_var].values\n",
    "        YStandard = StandardScaler()\n",
    "        self.YScaled = YStandard.fit(self.y.reshape(-1, 1))\n",
    "        Yscale = self.YScaled.transform(self.y.reshape(-1, 1))\n",
    "        self.y = np.ndarray.flatten(Yscale)\n",
    "        self.Ytru = self.YScaled.inverse_transform(self.y.reshape(-1,1))\n",
    "        X = self.Data[X_vars]\n",
    "        self.input_shape = len(X_vars)\n",
    "        XStandard = StandardScaler()\n",
    "        self.XScaled= XStandard.fit(X)\n",
    "        self.X = self.XScaled.transform(X)\n",
    "        Filling = self.Master[X_vars]\n",
    "        Filling = Filling.interpolate().bfill()\n",
    "        Filling = Filling.interpolate().ffill()\n",
    "        XStandard = StandardScaler()\n",
    "        self.XFillScaled= XStandard.fit(Filling)\n",
    "        self.X_fill = self.XScaled.transform(Filling)\n",
    "        \n",
    "    def TimeShape(self,rolls):\n",
    "        X1 = self.X\n",
    "        Xf = self.X_fill\n",
    "        self.X_time = np.zeros(shape = (X1.shape[0],rolls+1,X1.shape[1]))\n",
    "        self.X_time[:,0,:] = X1\n",
    "        self.X_ftime = np.zeros(shape = (Xf.shape[0],rolls+1,Xf.shape[1]))\n",
    "        self.X_ftime[:,0,:] = Xf\n",
    "        if rolls > 0:\n",
    "            for roll in range(0,rolls):\n",
    "                X2 = np.roll(X1,(roll+1),axis=0)\n",
    "                X2f = np.roll(Xf,(roll+1),axis=0)\n",
    "                self.X_time[:,roll+1,:] = X2\n",
    "                self.X_ftime[:,roll+1,:] = Xf\n",
    "        self.X_time = self.X_time[rolls+1:,:,:]\n",
    "        self.X_ftime = self.X_ftime[rolls+1:,:,:]\n",
    "        self.y_time = self.y[rolls+1:]\n",
    "        self.y_ftime = self.y[rolls+1:]\n",
    "        self.TimeSteps = rolls+1\n",
    "        \n",
    "    def Fill(self,Y_Pred):\n",
    "        Y_fill = self.YScaled.inverse_transform(Y_Pred.reshape(-1,1))\n",
    "        nanz = np.zeros(shape=(self.TimeSteps,1))\n",
    "        nanz[:,:] = np.nan\n",
    "        Y_Pred = np.concatenate((nanz,Y_fill),axis=0).reshape(-1,1)\n",
    "        self.Master['TempFIll'] = Y_Pred\n",
    "        self.Master[self.y_var+'_Filled'] = self.Master[self.y_var].fillna(self.Master['TempFIll'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LSTM_Model(Neurons,batch_size,time_steps,inputs,lr=1e-4,Memory=.9):\n",
    "    import keras\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    from keras.layers import LSTM\n",
    "    from keras.wrappers.scikit_learn import KerasRegressor\n",
    "    from keras.callbacks import EarlyStopping,ModelCheckpoint,LearningRateScheduler\n",
    "#     from keras import backend as K\n",
    "    import tensorflow as tf\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = Memory\n",
    "    session = tf.Session(config=config)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(Neurons, input_shape=(time_steps,inputs),stateful = False))\n",
    "    model.add(Dense(1))\n",
    "    NUM_GPU = 1 # or the number of GPUs available on your machine\n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr = lr)\n",
    "    gpu_list = []\n",
    "    for i in range(NUM_GPU): gpu_list.append('gpu(%d)' % i)\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')#,context=gpu_list) # - Add if using MXNET\n",
    "    return(model)\n",
    "\n",
    "def Train_Steps(epochs,Neurons,X_train,X_test,X_val,y_train,y_test,y_val,rs,i=None,Memory=None):\n",
    "    \n",
    "    np.random.seed(i)\n",
    "    from keras import backend as K\n",
    "#     epochs = 100\n",
    "    Scorez=[]\n",
    "    lr = 1e-3\n",
    "    Mod = LSTM_Model(Neurons,X_train.shape[0],X_train.shape[1],X_train.shape[2],lr=lr,Memory=Memory)\n",
    "    killscore=0\n",
    "    killmax = 10\n",
    "    e = 0\n",
    "    udate = 3\n",
    "    np.random.seed(rs)\n",
    "    while killscore < killmax and e < epochs:\n",
    "#         print(e)\n",
    "        Mod.fit(X_train,y_train,batch_size=X_train.shape[0], nb_epoch=1,shuffle=True,verbose=0)\n",
    "        old_weights = Mod.get_weights()\n",
    "        Y = Mod.predict(X_test,batch_size =X_test.shape[0])\n",
    "        score = metrics.mean_squared_error(y_test,Y)\n",
    "        Scorez.append(score)\n",
    "        if e == 0:\n",
    "            score_min=score\n",
    "            min_weights=old_weights\n",
    "        elif score < score_min:\n",
    "            score_min = score\n",
    "            min_weights=old_weights\n",
    "            killscore = 0\n",
    "        else:\n",
    "            killscore +=1\n",
    "        if killscore == math.floor(killmax/2):\n",
    "            K.set_value(Mod.optimizer.lr, 0.5 * K.get_value(Mod.optimizer.lr))\n",
    "#             print(K.get_value(Mod.optimizer.lr))\n",
    "        Mod.reset_states()\n",
    "        e +=1\n",
    "#         print(e,killscore)\n",
    "    Mod.set_weights(min_weights)\n",
    "    Yval = Mod.predict(X_val,batch_size = X_val.shape[0])\n",
    "    MSE = (metrics.mean_squared_error(y_val,Yval))\n",
    "    Scorez=np.asanyarray(Scorez)\n",
    "    return(MSE,min_weights)\n",
    "           \n",
    "# def RunFunc(i,processes,Modz,reps,time_steps,Neurons,epochs):\n",
    "def RunFunc(i,processes,Modz,params):\n",
    "#     print(params.iloc[i])\n",
    "    time_steps = params['T']#.iloc[i]\n",
    "    Neurons = params['N']#.iloc[i]\n",
    "#     np.random.seed(i)\n",
    "    Path = 'QuickData_FI.csv' \n",
    "#     CH4_Model = ['Sedge','Temp','VWC','ustar','air_pressure','PPFD_Avg']\n",
    "    RST = ReadStandardTime(Path)\n",
    "    offset = 5/processes\n",
    "    Memory = (math.floor(100/processes)- offset) * .01\n",
    "    MSE = []\n",
    "\n",
    "#     Model=\n",
    "    RST.Scale('co2_flux',Modz[i])\n",
    "    RST.TimeShape(time_steps)\n",
    "    y = RST.y_time*1.0\n",
    "    X = RST.X_time*1.0\n",
    "    for r in range(params['reps']):\n",
    "        X_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.1, random_state=r)\n",
    "        X_train,X_val,y_train,y_val=train_test_split(X_train,y_train, test_size=0.11, random_state=r)\n",
    "        mse,w=Train_Steps(params['epochs'],Neurons,X_train,X_test,X_val,y_train,y_test,y_val,rs=i,i=r,Memory=Memory)\n",
    "        MSE.append(mse)\n",
    "    mse = np.asanyarray(MSE)\n",
    "    mse,std = mse.mean(),mse.std()\n",
    "    return(mse,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N': 60, 'reps': 2, 'epochs': 100, 'T': 1}\n"
     ]
    }
   ],
   "source": [
    "class Params:\n",
    "    def __init__(self,Func,samp_size):\n",
    "        if Func == 'Quick':            \n",
    "            epochs = 1000\n",
    "            reps = 10\n",
    "            N = 300\n",
    "            T = 6\n",
    "        elif Func == 'Full':\n",
    "            epochs = 2000\n",
    "            reps = 100\n",
    "            N = 200\n",
    "            T = 12\n",
    "        else:\n",
    "            epochs = 100\n",
    "            reps = 2\n",
    "            N = 60\n",
    "            T = 1\n",
    "#         N = np.array(np.random.rand(samp_size)*N_Max,dtype='int32')\n",
    "#         T = np.array(np.random.rand(samp_size)*T_Max,dtype='int32')\n",
    "#         d = {'N':N,'T':T}\n",
    "#         self.Runs = pd.DataFrame(data=d)\n",
    "#         self.reps = reps\n",
    "#         self.epochs= epochs\n",
    "#         self.T_Max = T_Max\n",
    "#         self.N_Max = N_Max\n",
    "        self.params = {}\n",
    "        self.params['T'] = T\n",
    "        self.params['N'] = N\n",
    "        self.params['reps'] = reps\n",
    "        self.params['epochs'] = epochs\n",
    "\n",
    "rpms = Params('temp',25)#'Quick Run')\n",
    "# Runs,reps,epochs = rpms.Runs,rpms.reps,rpms.epochs\n",
    "params=rpms.params\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Temp_2_5_1', 'Temp_2_5_2', 'u*', 'wind_speed', 'air_pressure']\n",
      "['Temp_2_5_1', 'Temp_2_5_2', 'u*', 'wind_speed', 'PPFD_Avg']\n",
      "['Temp_2_5_1', 'Temp_2_5_2', 'u*', 'air_pressure', 'PPFD_Avg']\n",
      "['Temp_2_5_1', 'Temp_2_5_2', 'wind_speed', 'air_pressure', 'PPFD_Avg']\n",
      "['Temp_2_5_1', 'u*', 'wind_speed', 'air_pressure', 'PPFD_Avg']\n",
      "['Temp_2_5_2', 'u*', 'wind_speed', 'air_pressure', 'PPFD_Avg']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d73dd86e5ac9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mScore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mScore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mScore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mScore\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mScore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "# Model = ['Temp_2_5_1','Temp_2_5_2','u*','wind_speed','air_pressure',\n",
    "#          'PPFD_Avg','NR_Wm2_Avg','AirTC_Avg','RH','DOY']\n",
    "Model = ['Temp_2_5_1','Temp_2_5_2','u*','wind_speed','air_pressure',\n",
    "         'PPFD_Avg']#,'NR_Wm2_Avg','AirTC_Avg','RH','DOY']\n",
    "Time = time.time()\n",
    "if __name__=='__main__':\n",
    "    processes=3\n",
    "    pool = Pool(processes=processes,maxtasksperchild=50)\n",
    "    Score = []\n",
    "    Models = []\n",
    "    L = len(Model)-1\n",
    "#     while L > len(Model-2):\n",
    "    for c in combinations(Model,L):\n",
    "        Models.append(list(c))\n",
    "    for i,res in enumerate(pool.imap(partial(RunFunc,processes=processes,Modz=Models,params=params),\n",
    "                                     range(len(Models)))):\n",
    "        print(Models[i])\n",
    "        Score.append(res[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Temp_2_5_1', 'Temp_2_5_2', 'wind_speed', 'air_pressure', 'PPFD_Avg']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Score = np.asanyarray(Score)\n",
    "print(Models[np.where(Score == Score.min())[0][0]])\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Model = ['Sedge','Shrubby','Temp','VWC','ustar','wind_speed','air_pressure',\n",
    "#          'PPFD_Avg','NR_Wm2_Avg','AirTC_Avg','RH','DOY']\n",
    "Model = ['Temp_2_5_1','Temp_2_5_2','u*','wind_speed','air_pressure',\n",
    "         'PPFD_Avg','NR_Wm2_Avg','AirTC_Avg','RH','DOY']\n",
    "Time = time.time()\n",
    "if __name__ == '__main__':  \n",
    "    results=[]\n",
    "    processes=3\n",
    "    pool = Pool(processes=processes,maxtasksperchild=50)\n",
    "    Results = []\n",
    "#     for i in Runs.index:\n",
    "#         res = RunFunc(i,processes=processes,Modz=Model,reps=reps,epochs=epochs,params=Runs)\n",
    "#         print(res)\n",
    "#         Runs['MSE'][i]=res[0]\n",
    "#         Runs['STD'][i]=res[1]\n",
    "    \n",
    "    for res in enumerate(pool.imap(partial(RunFunc,processes=processes,Modz=Model,reps=reps,\n",
    "                                           epochs=epochs,params=Runs),Runs.index)):\n",
    "        print(res)\n",
    "        Runs['MSE'][res[0]]=res[1][0]\n",
    "        Runs['STD'][res[0]]=res[1][1]\n",
    "#         data = [N,res[0],res[1][0],res[1][1]]\n",
    "# #             mse,std = RunFunc(T,processes,Model,rpms.reps,N,rpms.epochs)\n",
    "# #             res = np.asanyarray([N,T,mse,std])\n",
    "#         RES.append(data)\n",
    "    print(Runs)\n",
    "    pool.close()\n",
    "    \n",
    "plt.figure()\n",
    "plt.scatter(Runs[\"N\"],Runs['T'],s=100,c=Runs['MSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "x = Runs[['N','T']].values\n",
    "y = Runs['MSE'].values\n",
    "s = Runs['STD'].values\n",
    "print(Runs)\n",
    "# print(x,y,s)\n",
    "# for i in [0,2,4]:\n",
    "#     idx = np.where(x == i)\n",
    "#     idx = np.where(x == i)[0]\n",
    "#     print(idx)\n",
    "#     print(x[idx,0])\n",
    "#     print(y[idx])\n",
    "\n",
    "#     plt.fill(np.concatenate([x[idx,0], (x[idx,0])[::-1]]),\n",
    "#              np.concatenate([y[idx] - s[idx], (y[idx] +  s[idx])[::-1]]),\n",
    "#              alpha=.2, fc='r', ec='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 8)\n",
    "def probability_of_improvement(mu_x, sigma_x, opt_value, kappa=0.5):\n",
    "    gamma_x = (mu_x - opt_value - kappa) / sigma_x\n",
    "    return norm.cdf(gamma_x)\n",
    "\n",
    "\n",
    "def expected_improvement(mu_x, sigma_x, opt_value, kappa=0.5):\n",
    "    gamma_x = (mu_x - opt_value - kappa) / sigma_x\n",
    "    return sigma_x * (gamma_x * norm.cdf(gamma_x) + norm.pdf(gamma_x))\n",
    "\n",
    "\n",
    "def upper_confidence_bound(mu_x, sigma_x, opt_value, kappa=-1.0):\n",
    "    return mu_x + kappa * sigma_x\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel\n",
    "\n",
    "kernel = Matern(length_scale = [50,3],length_scale_bounds=\"fixed\")\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=s, random_state=0,normalize_y=False)\n",
    "gp.fit(x, y)\n",
    "\n",
    "N = [n for n in range(rpms.N_Max)]\n",
    "T = [t for t in range(rpms.T_Max)]\n",
    "A = [T[i] for j in range(len(N))for i in range(len(T))]\n",
    "B = [N[i] for j in range(len(T))for i in range(len(N))]\n",
    "T = np.asanyarray(A)\n",
    "N = np.asanyarray(B)\n",
    "\n",
    "X = np.zeros(shape=(T.shape[0],2))\n",
    "X[:,0] = N\n",
    "X[:,1] = T\n",
    "y_pred,sigma = gp.predict(X,return_std=True)\n",
    "print(y_pred.shape,sigma.shape)\n",
    "# for t in range(T.max()+1):\n",
    "#     t+=1\n",
    "#     plt.figure()\n",
    "#     plt.plot(X[(t-1)*N.shape[0]:t*N.shape[0],0],y_pred[(t-1)*N.shape[0]:t*N.shape[0]])\n",
    "# #     print(y_pred[(t-1)*N.shape[0]:t*N.shape[0]])\n",
    "#     plt.fill(np.concatenate([X[(t-1)*N.shape[0]:t*N.shape[0],0], (X[(t-1)*N.shape[0]:t*N.shape[0],0])[::-1]]),\n",
    "#              np.concatenate([y_pred[(t-1)*N.shape[0]:t*N.shape[0]] - sigma[(t-1)*N.shape[0]:t*N.shape[0]],\n",
    "#                              (y_pred[(t-1)*N.shape[0]:t*N.shape[0]] +  sigma[(t-1)*N.shape[0]:t*N.shape[0]])[::-1]]),\n",
    "#              alpha=.2, fc='r', ec='None')\n",
    "# plt.plot(X[:199,0],y_pred[:199])\n",
    "# plt.plot(X[200:399,0],y_pred[200:399])\n",
    "# plt.plot(X[400:599,0],y_pred[400:599])\n",
    "# print(X[:200,0].shape,y_pred[:200].shape)\n",
    "# plot(x, y, gp, filename=\"fig2.pdf\")\n",
    "# print(y_pred)\n",
    "# print(y_pred.shape)\n",
    "plt.figure()\n",
    "plt.scatter(X[:,0],X[:,1],c=y_pred)\n",
    "plt.legend()\n",
    "Runs2 = Runs.copy()\n",
    "# Y = y_pred.reshape(rpms.T_Max,rpms.N_Max)#[:,::-1]\n",
    "# print(Y)\n",
    "# # print(Y.shape)\n",
    "# plt.figure()\n",
    "# plt.imshow(Y[::-1])\n",
    "# plt.colorbar()\n",
    "# print(y_pred)\n",
    "\n",
    "print(rpms.T_Max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cap = 220\n",
    "MaxT = 6\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "acq = upper_confidence_bound\n",
    "\n",
    "def query(xi, yi, gp):\n",
    "    best_value = np.inf\n",
    "\n",
    "    for N in np.linspace(1,Cap):\n",
    "        for T in np.linspace(0,MaxT):\n",
    "            def obj(x):\n",
    "                x=x.reshape(1,-1)\n",
    "                mu_x, sigma_x = gp.predict(x, return_std=True)\n",
    "#                 print(np.min(yi),np.max(yi))\n",
    "                return acq(mu_x, sigma_x, np.min(yi))\n",
    "            x0 = np.asanyarray([N,T]).reshape(1,2)\n",
    "            res = minimize(obj, x0, bounds=((1, Cap),(0,MaxT)))\n",
    "\n",
    "            if res.fun < best_value:\n",
    "                best_value = res.fun\n",
    "                query_point = res.x\n",
    "    query_point = query_point\n",
    "    return query_point\n",
    "for i in range(5):\n",
    "    kernel = Matern(length_scale_bounds=\"fixed\") \n",
    "    gp = GaussianProcessRegressor(kernel=kernel, alpha=s, random_state=1,normalize_y=True)\n",
    "    gp.fit(x, y)\n",
    "    \n",
    "    next_x = query(x, y, gp)\n",
    "    print(next_x)\n",
    "    N = int(np.round(next_x[0],0))\n",
    "    T = int(np.round(next_x[1],0))\n",
    "    o = 0\n",
    "    while len(Runs.loc[(Runs['N']==N) & (Runs['T']==T)].index) != 0:\n",
    "        print('Adjust!')\n",
    "        o +=1\n",
    "        N += int(o*np.cos(o*np.pi))\n",
    "    print(N,T)\n",
    "    d = {'N':N,'T':T,'MSE':0,'STD':0}\n",
    "    idx = Runs.index[-1] + 1\n",
    "    D2 = pd.DataFrame(data=d,index=[idx])\n",
    "    Runs = Runs.append(D2)\n",
    "    \n",
    "    res = RunFunc(idx,processes=processes,Modz=Model,reps=reps,epochs=epochs,params=Runs)\n",
    "    print(res)\n",
    "    Runs['MSE'][idx]=res[0]\n",
    "    Runs['STD'][idx]=res[1]\n",
    "    Runs = Runs.sort_values(by = ['N','T']).reset_index(drop=True)\n",
    "    \n",
    "    x = Runs[['N','T']].values\n",
    "    y = Runs['MSE'].values\n",
    "    s = Runs['STD'].values\n",
    "    \n",
    "print(Runs)\n",
    "#     res = RunFunc(i,processes=processes,Modz=Model,reps=reps,epochs=epochs,params=Runs)\n",
    "#     print(res)\n",
    "#     Runs['MSE'][i]=res[0]\n",
    "#     Runs['STD'][i]=res[1]\n",
    "#     if N in Runs['N']:\n",
    "#         o = 0\n",
    "#         while next_x in Res[:,0] and next_x < Cap and next_x > 0:\n",
    "#             o +=1\n",
    "#             next_x += int(o*np.cos(o*np.pi))\n",
    "#             print(next_x)\n",
    "    \n",
    "#     mse,std = RunFunc(int(next_x[1]),processes,Model,reps,int(next_x[0]),epochs)\n",
    "#     res = np.asanyarray([N,T,mse,std])\n",
    "#     RES.append(res)\n",
    "# #         MSE.append(mse)\n",
    "# #         STD.append(std)\n",
    "#     Res = np.asanyarray(RES)\n",
    "#     Res = Res[np.argsort(Res[:,0],axis=0),:]\n",
    "# #     Res = Res[Res[:, 0].argsort()]\n",
    "# #     Res.view('i8,i8,i8').sort(order=['f0'], axis=1)\n",
    "#     print(Res)\n",
    "#     plt.plot(Res[:,0],Res[:,1],marker = '*')\n",
    "#     x = Res[:,0]\n",
    "#     y = Res[:,1]\n",
    "#     s = Res[:,2]\n",
    "#     print(x,y)\n",
    "# plt.fill(np.concatenate([x, x[::-1]]),\n",
    "#          np.concatenate([y - s, (y +  s)[::-1]]),\n",
    "#          alpha=.2, fc='r', ec='None')\n",
    "#     plot(x, y, gp, acq=acq, next_x=next_x, filename=\"fig4-%d.pdf\" % i)\n",
    "    \n",
    "#     x = np.vstack((x, next_x))\n",
    "#     yi = np.concatenate((y, noise_f(xi[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
